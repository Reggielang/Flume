三、Flume事务
数据输入端
Put事务流程
doPut:将批数据先写入临时缓冲区putList
doCommit:检查channel内存队列是否足够合并。
doRollback:channel内存队列空间不足，回滚数据

数据输出端
Take事务
doTake:将数据取到临时缓冲区takeList，并将数据发送到HDFS
doCommit:如果数据全部发送成功，则清除临时缓冲区takeList
doRollback:数据发送过程中如果出现异常，rollback将临时缓冲区takeList中的数据归还给channel内存队列。

Flume Agent内部原理
1 接收数据
2 处理事件
3 将事件传递给拦截器链！
4 将每个事件给Channel选择器
Channel Selectors有两种类型:Replicating Channel Selector (default)和Multiplexing Channel Selector。Replicating 会将source过来的events发往所有channel,而Multiplexing可以配置发往哪些Channel。
5 返回写入事件Channel列表
6 根据Channel选择器的选择结果，将事件写入相应Channel。
7 SinkProcessor有三种：
DefaultSinkProcessor、LoadBalancingSinkProcessor、FailoverSinkProcessor
每种都有其各自的功能

重要组件：
1）ChannelSelector
ChannelSelector的作用就是选出Event将要被发往哪个Channel。其共有两种类型，分别是Replicating（复制）和Multiplexing（多路复用）。
ReplicatingSelector会将同一个Event发往所有的Channel，Multiplexing会根据相应的原则，将不同的Event发往不同的Channel。
2）SinkProcessor
SinkProcessor共有三种类型，分别是DefaultSinkProcessor、LoadBalancingSinkProcessor、FailoverSinkProcessor 
DefaultSinkProcessor对应的是单个的Sink，LoadBalancingSinkProcessor和FailoverSinkProcessor对应的是Sink Group，LoadBalancingSinkProcessor可以实现负载均衡的功能，FailoverSinkProcessor可以错误恢复的功能。

Flume拓扑结构
简单串联
这种模式是将多个flume顺序连接起来了，从最初的source开始到最终sink传送的目的存储系统。此模式不建议桥接过多的flume数量， flume数量过多不仅会影响传输速率，而且一旦传输过程中某个节点flume宕机，会影响整个传输系统。

复制和多路复用
Flume支持将事件流向一个或者多个目的地。这种模式可以将相同数据复制到多个channel中，或者将不同数据分发到不同的channel中，sink可以选择传送到不同的目的地。

负载均衡和故障转移
Flume支持使用将多个sink逻辑上分到一个sink组，sink组配合不同的SinkProcessor可以实现负载均衡和错误恢复的功能。

聚合
这种模式是我们最常见的，也非常实用，日常web应用通常分布在上百个服务器，大者甚至上千个、上万个服务器。产生的日志，处理起来也非常麻烦。用flume的这种组合方式能很好的解决这一问题，每台服务器部署一个flume采集日志，传送到一个集中收集日志的flume，再由此flume上传到hdfs、hive、hbase等，进行日志分析。

Flume企业开发案例
1 复制和多路复用
1）案例需求
使用Flume-1监控文件变动，Flume-1将变动内容传递给Flume-2，Flume-2负责存储到HDFS。同时Flume-1将变动内容传递给Flume-3，Flume-3负责输出到Local FileSystem。
flume1.conf
#Named
a1.sources=r1
a1.channels = c1 c2
a1.sinks = k1
#Source
a1.sources.r1.type=TAILDIR
a1.sources.r1.filegroups=f1
a1.sources.r1.filegroups.f1=/opt/module/flume-1.9.0/jobs/taildir/.*\.txt
a1.sources.r1.positionFile=/opt/module/flume-1.9.0/jobs/position/position.json

#channel selector
a1.sources.r1.selector.type=replicating

#Channel
a1.channels.c1.type=memory
a1.channels.c1.capacity=10000
a1.channels.c1.transactionCapacity=100

a1.channels.c2.type=memory
a1.channels.c2.capacity=10000
a1.channels.c2.transactionCapacity=100

#Sink
a1.sinks.k1.type=avro
a1.sinks.k1.hostname=localhost
a1.sinks.k1.port = 7777

a1.sinks.k2.type=avro
a1.sinks.k2.hostname=localhost
a1.sinks.k2.port = 8888
 
#Bind
a1.sources.r1.channels=c1 c2
a1.sinks.k1.channel=c1
a1.sinks.k2.channel=c2

flume2.conf
#Named
a2.sources=r1
a2.channels = c1
a2.sinks = k1

#Source
a2.sources.r1.type=avro
a2.sources.r1.bind = localhost
a2.sources.r1.port = 7777
#Channel
a2.channels.c1.type=memory
a2.channels.c1.capacity=10000
a2.channels.c1.transactionCapacity=100
#Sink
a2.sinks.k1.type = hdfs
a2.sinks.k1.hdfs.path = hdfs://hadoop102:8020/flume/%Y%m%d/%H
#上传文件的前缀
a2.sinks.k1.hdfs.filePrefix = logs-
#是否按照时间滚动文件夹
a2.sinks.k1.hdfs.round = true
#多少时间单位创建一个新的文件夹
a2.sinks.k1.hdfs.roundValue = 1
#重新定义时间单位
a2.sinks.k1.hdfs.roundUnit = hour
#是否使用本地时间戳
a2.sinks.k1.hdfs.useLocalTimeStamp = true
#积攒多少个Event才flush到HDFS一次
a2.sinks.k1.hdfs.batchSize = 100
#设置文件类型，可支持压缩
a2.sinks.k1.hdfs.fileType = DataStream
#多久生成一个新的文件
a2.sinks.k1.hdfs.rollInterval = 60
#设置每个文件的滚动大小
a2.sinks.k1.hdfs.rollSize = 134217700
#文件的滚动与Event数量无关
a2.sinks.k1.hdfs.rollCount = 0
#Bind
a2.sources.r1.channels=c1
a2.sinks.k1.channel=c1

flume3.conf
#Named
a3.sources=r1
a3.channels = c1
a3.sinks = k1

#Source
a3.sources.r1.type=avro
a3.sources.r1.bind = localhost
a3.sources.r1.port = 8888
#Channel
a3.channels.c1.type=memory
a3.channels.c1.capacity=10000
a3.channels.c1.transactionCapacity=100
#Sink
a3.sinks.k1.type=file_roll
a3.sinks.k1.sink.directory = /opt/module/flume-1.9.0/jobs/fileroll
#Bind
a3.sources.r1.channels=c1
a3.sinks.k1.channel=c1

2 负载均衡和故障转移
1）案例需求
使用Flume1监控一个端口，其sink组中的sink分别对接Flume2和Flume3,然后使用负载均衡

flume1.conf
#Named
a1.sources=r1
a1.channels = c1
a1.sinks = k1 k2
#Source
a1.sources.r1.type=netcat
a1.sources.r1.bind=localhost
a1.sources.r1.port=6666

#channel selector
a1.sources.r1.selector.type=replicating

#Channel
a1.channels.c1.type=memory
a1.channels.c1.capacity=10000
a1.channels.c1.transactionCapacity=100

#Sink
a1.sinks.k1.type=avro
a1.sinks.k1.hostname=localhost
a1.sinks.k1.port = 7777

a1.sinks.k2.type=avro
a1.sinks.k2.hostname=localhost
a1.sinks.k2.port = 8888

#sink processor
a1.sinkgroups=g1
a1.sinkgroups.g1.sinks= k1 k2
a1.sinkgroups.g1.processor.type=load_balance
a1.sinkgroups.g1.processor.selector=round_robin

#Bind
a1.sources.r1.channels=c1
a1.sinks.k1.channel=c1
a1.sinks.k2.channel=c1

flume2.conf
#Named
a2.sources=r1
a2.channels = c1
a2.sinks = k1

#Source
a2.sources.r1.type=avro
a2.sources.r1.bind = localhost
a2.sources.r1.port = 7777

#Channel
a2.channels.c1.type=memory
a2.channels.c1.capacity=10000
a2.channels.c1.transactionCapacity=100

#Sink
a2.sinks.k1.type =logger

#Bind
a2.sources.r1.channels=c1
a2.sinks.k1.channel=c1

flume3.conf
#Named
a3.sources=r1
a3.channels = c1
a3.sinks = k1

#Source
a3.sources.r1.type=avro
a3.sources.r1.bind = localhost
a3.sources.r1.port = 8888
#Channel
a3.channels.c1.type=memory
a3.channels.c1.capacity=10000
a3.channels.c1.transactionCapacity=100
#Sink
a3.sinks.k1.type=logger

#Bind
a3.sources.r1.channels=c1
a3.sinks.k1.channel=c1

故障转移
1）案例需求
使用Flume1监控一个端口，其sink组中的sink分别对接Flume2和Flume3，采用FailoverSinkProcessor，实现故障转移的功能。

flume1.conf
#Named
a1.sources=r1
a1.channels = c1
a1.sinks = k1 k2
#Source
a1.sources.r1.type=netcat
a1.sources.r1.bind=localhost
a1.sources.r1.port=6666

#channel selector
a1.sources.r1.selector.type=replicating

#Channel
a1.channels.c1.type=memory
a1.channels.c1.capacity=10000
a1.channels.c1.transactionCapacity=100

#Sink
a1.sinks.k1.type=avro
a1.sinks.k1.hostname=localhost
a1.sinks.k1.port = 7777

a1.sinks.k2.type=avro
a1.sinks.k2.hostname=localhost
a1.sinks.k2.port = 8888

#sink processor
a1.sinkgroups=g1 
a1.sinkgroups.g1.sinks= k1 k2
a1.sinkgroups.g1.processor.type=failover
a1.sinkgroups.g1.processor.priority.k1=5
a1.sinkgroups.g1.processor.priority.k2=10

#Bind
a1.sources.r1.channels=c1
a1.sinks.k1.channel=c1
a1.sinks.k2.channel=c1

flume2.conf
#Named
a2.sources=r1
a2.channels = c1
a2.sinks = k1

#Source
a2.sources.r1.type=avro
a2.sources.r1.bind = localhost
a2.sources.r1.port = 7777

#Channel
a2.channels.c1.type=memory
a2.channels.c1.capacity=10000
a2.channels.c1.transactionCapacity=100

#Sink
a2.sinks.k1.type =logger

#Bind
a2.sources.r1.channels=c1
a2.sinks.k1.channel=c1

flume3.conf
#Named
a3.sources=r1
a3.channels = c1
a3.sinks = k1

#Source
a3.sources.r1.type=avro
a3.sources.r1.bind = localhost
a3.sources.r1.port = 8888
#Channel
a3.channels.c1.type=memory
a3.channels.c1.capacity=10000
a3.channels.c1.transactionCapacity=100
#Sink
a3.sinks.k1.type=logger

#Bind
a3.sources.r1.channels=c1
a3.sinks.k1.channel=c1

聚合
1）案例需求：
hadoop102上的Flume-1监控文件/opt/module/group.log，
hadoop103上的Flume-2监控某一个端口的数据流，
Flume-1与Flume-2将数据发送给hadoop104上的Flume-3，Flume-3将最终数据打印到控制台。

flume1.conf
#Named
a1.sources=r1
a1.channels = c1
a1.sinks = k1
#Source
a1.sources.r1.type=TAILDIR
a1.sources.r1.filegroups=f1
a1.sources.r1.filegroups.f1=/opt/module/flume-1.9.0/jobs/taildir/.*\.txt
a1.sources.r1.positionFile=/opt/module/flume-1.9.0/jobs/position/position.json

#channel selector
a1.sources.r1.selector.type=replicating

#Channel
a1.channels.c1.type=memory
a1.channels.c1.capacity=10000
a1.channels.c1.transactionCapacity=100

#Sink
a1.sinks.k1.type=avro
a1.sinks.k1.hostname=hadoop104
a1.sinks.k1.port = 8888


#Bind
a1.sources.r1.channels=c1
a1.sinks.k1.channel=c1


flume2.conf
#Named
a2.sources=r1
a2.channels = c1
a2.sinks = k1

#Source
a2.sources.r1.type=netcat
a2.sources.r1.bind = localhost
a2.sources.r1.port = 6666

#Channel
a2.channels.c1.type=memory
a2.channels.c1.capacity=10000
a2.channels.c1.transactionCapacity=100

#Sink
a2.sinks.k1.type =avro
a2.sinks.k1.hostname=hadoop104
a2.sinks.k1.port= 8888

#Bind
a2.sources.r1.channels=c1
a2.sinks.k1.channel=c1

flume3.conf
#Named
a3.sources=r1
a3.channels = c1
a3.sinks = k1

#Source
a3.sources.r1.type=avro
a3.sources.r1.bind = hadoop104
a3.sources.r1.port = 8888
#Channel
a3.channels.c1.type=memory
a3.channels.c1.capacity=10000
a3.channels.c1.transactionCapacity=100
#Sink
a3.sinks.k1.type=logger

#Bind
a3.sources.r1.channels=c1
a3.sinks.k1.channel=c1

自定义Interceptor
3.5 自定义Interceptor
1）案例需求
使用Flume采集服务器本地日志，需要按照日志类型的不同，将不同种类的日志发往不同的分析系统。
2）需求分析
在实际的开发中，一台服务器产生的日志类型可能有很多种，不同类型的日志可能需要发送到不同的分析系统。此时会用到Flume拓扑结构中的Multiplexing结构，Multiplexing的原理是，根据event中Header的某个key的值，将不同的event发送到不同的Channel中，所以我们需要自定义一个Interceptor，为不同类型的event的Header中的key赋予不同的值。
以端口数据模拟日志，以数字（单个）和字母（单个）模拟不同类型的日志，我们需要自定义interceptor区分数字和字母，将其分别发往不同的分析系统（Channel）。
Flume1监控端口的数据，将监控到的数据发给flume2，flume3，flume4，包含“honglang”发给flume2 ,"bushi"发给flume3，其他数据发给flume4
flume1.conf
#Named
a1.sources=r1
a1.channels = c1 c2 c3
a1.sinks = k1 k2 k3
#Source
a1.sources.r1.type=netcat
a1.sources.r1.bind = localhost
a1.sources.r1.port = 5555

#channel selector
a1.sources.r1.selector.type=multiplexing
a1.sources.r1.selector.header = title
a1.sources.r1.selector.mapping.at = c1
a1.sources.r1.selector.mapping.bt = c2
a1.sources.r1.selector.default = c3

#Interceptor
a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type =flume.interceptor.EventHeaderInterceptor$MyBuilder

#Channel
a1.channels.c1.type=memory
a1.channels.c1.capacity=10000
a1.channels.c1.transactionCapacity=100

a1.channels.c2.type=memory
a1.channels.c2.capacity=10000
a1.channels.c2.transactionCapacity=100

a1.channels.c3.type=memory
a1.channels.c3.capacity=10000
a1.channels.c3.transactionCapacity=100

#Sink
a1.sinks.k1.type=avro
a1.sinks.k1.hostname=localhost
a1.sinks.k1.port = 6666

a1.sinks.k2.type=avro
a1.sinks.k2.hostname=localhost
a1.sinks.k2.port = 7777

a1.sinks.k3.type=avro
a1.sinks.k3.hostname=localhost
a1.sinks.k3.port = 8888
 
#Bind
a1.sources.r1.channels=c1 c2 c3
a1.sinks.k1.channel=c1
a1.sinks.k2.channel=c2
a1.sinks.k3.channel=c3

flume2.conf
#Named
a2.sources=r1
a2.channels = c1
a2.sinks = k1

#Source
a2.sources.r1.type=avro
a2.sources.r1.bind = localhost
a2.sources.r1.port = 6666
#Channel
a2.channels.c1.type=memory
a2.channels.c1.capacity=10000
a2.channels.c1.transactionCapacity=100
#Sink
a2.sinks.k1.type =logger
#Bind
a2.sources.r1.channels=c1
a2.sinks.k1.channel=c1

flume3.conf
#Named
a3.sources=r1
a3.channels = c1
a3.sinks = k1

#Source
a3.sources.r1.type=avro
a3.sources.r1.bind = localhost
a3.sources.r1.port = 7777
#Channel
a3.channels.c1.type=memory
a3.channels.c1.capacity=10000
a3.channels.c1.transactionCapacity=100
#Sink
a3.sinks.k1.type=logger
#Bind
a3.sources.r1.channels=c1
a3.sinks.k1.channel=c1

flume4.conf
#Named
a4.sources=r1
a4.channels = c1
a4.sinks = k1

#Source
a4.sources.r1.type=avro
a4.sources.r1.bind = localhost
a4.sources.r1.port = 8888
#Channel
a4.channels.c1.type=memory
a4.channels.c1.capacity=10000
a4.channels.c1.transactionCapacity=100
#Sink
a4.sinks.k1.type=logger
#Bind
a4.sources.r1.channels=c1
a4.sinks.k1.channel=c1


3.6 自定义Source
1）介绍
Source是负责接收数据到Flume Agent的组件。Source组件可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy。官方提供的source类型已经很多，但是有时候并不能满足实际开发当中的需求，此时我们就需要根据实际需求自定义某些source。

https://flume.apache.org/FlumeDeveloperGuide.html#source
根据官方说明自定义MySource需要继承AbstractSource类并实现Configurable和PollableSource接口。
实现相应方法：
getBackOffSleepIncrement() //backoff 步长
getMaxBackOffSleepInterval()//backoff 最长时间
configure(Context context)//初始化context（读取配置文件内容）
process()//获取数据封装成event并写入channel，这个方法将被循环调用。
使用场景：读取MySQL数据或者其他文件系统。

需求
使用flume接收数据，并给每条数据添加前缀，输出到控制台。前缀可从flume配置文件中配置。

flume1.conf
#Named
a1.sources=r1
a1.channels = c1
a1.sinks = k1

#Source
a1.sources.r1.type=flume.interceptor.MySource
a1.sources.r1.prefix = log --
#Channel
a1.channels.c1.type=memory
a1.channels.c1.capacity=10000
a1.channels.c1.transactionCapacity=100
#Sink
a1.sinks.k1.type=logger
#Bind
a1.sources.r1.channels=c1
a1.sinks.k1.channel=c1


自定义sink
flume1.conf
#Named
a1.sources=r1
a1.channels = c1
a1.sinks = k1

#Source
a1.sources.r1.type=flume.interceptor.MySource
a1.sources.r1.prefix = log --
#Channel
a1.channels.c1.type=memory
a1.channels.c1.capacity=10000
a1.channels.c1.transactionCapacity=100
#Sink
a1.sinks.k1.type=flume.interceptor.MySink
#Bind
a1.sources.r1.channels=c1
a1.sinks.k1.channel=c1


Flume数据流监控
Ganglia的安装与部署
Ganglia由gmond、gmetad和gweb三部分组成。
gmond（Ganglia Monitoring Daemon）是一种轻量级服务，安装在每台需要收集指标数据的节点主机上。使用gmond，你可以很容易收集很多系统指标数据，如CPU、内存、磁盘、网络和活跃进程的数据等。gmetad（Ganglia Meta Daemon）整合所有信息，并将其以RRD格式存储至磁盘的服务。gweb（Ganglia Web）Ganglia可视化工具，gweb是一种利用浏览器显示gmetad所存储数据的PHP前端。在Web界面中以图表方式展现集群的运行状态下收集的多种不同指标数据。

1）安装ganglia
（1）规划
hadoop102:     gweb  gmetad gmod 
hadoop103:     gmod
hadoop104:     gmod


在102修改配置文件/etc/httpd/conf.d/ganglia.conf
在102修改配置文件/etc/ganglia/gmetad.conf
在102 103 104修改配置文件/etc/ganglia/gmond.conf
在102修改配置文件/etc/selinux/config

监控窗口：http://hadoop102/ganglia/

操作Flume测试监控
1）启动Flume任务
flume-ng agent \
-c $FLUME_HOME/conf \
-n a1 \
-f $FLUME_HOME/jobs/netcat-flume-logger.conf \
-Dflume.root.logger=INFO,console \
-Dflume.monitoring.type=ganglia \
-Dflume.monitoring.hosts=hadoop102:8649

 企业真实面试题
章 企业真实面试题（重点）
如何实现Flume数据传输的监控的
使用第三方框架Ganglia实时监控Flume。

4.2 Flume的Source，Sink，Channel的作用？你们Source是什么类型？
1）作用
（1）Source组件是专门用来收集数据的，可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy
（2）Channel组件对采集到的数据进行缓存，可以存放在Memory或File中。
（3）Sink组件是用于把数据发送到目的地的组件，目的地包括Hdfs、Logger、avro、thrift、ipc、file、Hbase、solr、自定义。
我公司采用的Source类型为：
（1）监控后台日志：exec
（2）监控后台产生日志的端口：netcat

Flume的Channel Selectors
这两种Selector的区别是:Replicating 会将source过来的events发往所有channel,而Multiplexing可以选择该发往哪些Channel。

4 Flume参数调优
1）Source
增加Source个（使用Tair Dir Source时可增加FileGroups个数）可以增大Source的读取数据的能力。例如：当某一个目录产生的文件过多时需要将这个文件目录拆分成多个文件目录，同时配置好多个Source 以保证Source有足够的能力获取到新产生的数据。
batchSize参数决定Source一次批量运输到Channel的event条数，适当调大这个参数可以提高Source搬运Event到Channel时的性能。

2）Channel 
type 选择memory时Channel的性能最好，但是如果Flume进程意外挂掉可能会丢失数据。type选择file时Channel的容错性更好，但是性能上会比memory channel差。使用file Channel时dataDirs配置多个不同盘下的目录可以提高性能。
Capacity 参数决定Channel可容纳最大的event条数。
transactionCapacity 参数决定每次Source往channel里面写的最大event条数和每次Sink从channel里面读的最大event条数。transactionCapacity需要大于Source和Sink的batchSize参数。

3）Sink 
增加Sink的个数可以增加Sink消费event的能力。Sink也不是越多越好够用就行，过多的Sink会占用系统资源，造成系统资源不必要的浪费。
batchSize参数决定Sink一次批量从Channel读取的event条数，适当调大这个参数可以提高Sink从Channel搬出event的性能。

Flume的事务机制
Flume的事务机制（类似数据库的事务机制）：Flume使用两个独立的事务分别负责从Soucrce到Channel，以及从Channel到Sink的事件传递。比如spooling directory source 为文件的每一行创建一个事件，一旦事务中所有的事件全部传递到Channel且提交成功，那么Soucrce就将该文件标记为完成。同理，事务以类似的方式处理从Channel到Sink的传递过程，如果因为某种原因使得事件无法记录，那么事务将会回滚。且所有的事件都会保持到Channel中，等待重新传递。

Flume采集数据会丢失吗?
根据Flume的架构原理，Flume是不可能丢失数据的，其内部有完善的事务机制，Source到Channel是事务性的，Channel到Sink是事务性的，因此这两个环节不会出现数据的丢失，唯一可能丢失数据的情况是Channel采用memoryChannel，agent宕机导致数据丢失，或者Channel存储数据已满，导致Source不再写入，未写入的数据丢失。

Flume不会丢失数据，但是有可能造成数据的重复，例如数据已经成功由Sink发出，但是没有接收到响应，Sink会再次发送数据，此时可能会导致数据的重复。